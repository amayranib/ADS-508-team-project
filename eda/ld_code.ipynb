{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ad2f1b1-2b8a-47f1-a93b-7a6c53374b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting httpimport\n",
      "  Using cached httpimport-1.4.1-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Using cached httpimport-1.4.1-py2.py3-none-any.whl (17 kB)\n",
      "Installing collected packages: httpimport\n",
      "Successfully installed httpimport-1.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install httpimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd1f525c-b0c7-463c-a30b-2bc723c96462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "import boto3 \n",
    "import sagemaker \n",
    "import httpimport \n",
    "import io \n",
    "\n",
    "from pyathena import connect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0dc2d89-0cfc-4e9a-a0f8-4ac07fa21329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize sagemaker sesssion and env var\n",
    "sess = sagemaker.Session() \n",
    "bucket = sess.default_bucket() \n",
    "role = sagemaker.get_execution_role() \n",
    "region = boto3.Session().region_name\n",
    "sm = boto3.client(\"sagemaker\", region_name=region) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e209d94-1b4d-4aa7-a1ff-c51f54df0c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public path: s3://usd-team1-ads508/ld_data/\n"
     ]
    }
   ],
   "source": [
    "# set s3 variables\n",
    "# s3 = boto3.client('s3')\n",
    "# bucket_name = 'jc-bucket-ads508-2025-finalproject'\n",
    "\n",
    "# file_benefits = './employee_benefits_2010_2024.csv'\n",
    "# s3_key_benefits = 'datasets/employee_benefits_2010_2024.csv'\n",
    "s3_public_path = \"s3://usd-team1-ads508/ld_data/\"\n",
    "s3_private_path = f\"s3://{bucket}/ld_data\"\n",
    "\n",
    "print(f\"Public path: {s3_public_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7359e76c-fc09-4401-b38e-7f60a1cd8704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import jcds \n",
    "with httpimport.github_repo('junclemente', 'jcds', ref='0.1.0'):\n",
    "    import jcds.eda as jeda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "800b3dff-b823-444d-b94c-4e7266d93f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset from s3 into dataframe\n",
    "# obj = s3.get_object(Bucket=bucket_name, Key=s3_key_benefits)\n",
    "# # read Excel file into dataframe\n",
    "# df = pd.read_csv(io.BytesIO(obj['Body'].read()))\n",
    "\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "208ef46b-8614-44e5-94e2-db7f51801e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 's3_public_path' (str)\n",
      "Stored 's3_private_path' (str)\n"
     ]
    }
   ],
   "source": [
    "# store paths\n",
    "%store s3_public_path\n",
    "%store s3_private_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d80d418-27ee-4854-8e33-0dbb4af2c58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy csv files from public to private bucket\n",
    "!aws s3 cp --recursive {s3_public_path} {s3_private_path}/ --include \"*.csv\" > /dev/null 2>&1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc4d075d-12ed-4651-ba9a-49b1e5c623bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   Key     Size (KB)             Last Modified\n",
      "0        ab_data/analytic_data2019.csv   8042.529297 2025-03-20 23:33:07+00:00\n",
      "1      ab_data/analytic_data2020_0.csv  11877.680664 2025-03-20 23:33:09+00:00\n",
      "2        ab_data/analytic_data2021.csv  12185.751953 2025-03-20 23:33:10+00:00\n",
      "3        ab_data/analytic_data2022.csv  12461.061523 2025-03-20 23:33:11+00:00\n",
      "4      ab_data/analytic_data2023_0.csv  12232.161133 2025-03-20 23:33:13+00:00\n",
      "5   jc_data/employee_benefits_2019.csv  22047.868164 2025-03-20 23:33:14+00:00\n",
      "6   jc_data/employee_benefits_2020.csv  18644.913086 2025-03-20 23:33:15+00:00\n",
      "7   jc_data/employee_benefits_2021.csv  21138.279297 2025-03-20 23:33:17+00:00\n",
      "8   jc_data/employee_benefits_2022.csv  20985.699219 2025-03-20 23:33:18+00:00\n",
      "9   jc_data/employee_benefits_2023.csv  21521.333008 2025-03-20 23:33:20+00:00\n",
      "10                 ld_data/adult19.csv  26104.992188 2025-03-20 23:33:21+00:00\n",
      "11                 ld_data/adult20.csv  29708.664062 2025-03-20 23:33:22+00:00\n",
      "12                 ld_data/adult21.csv  27322.115234 2025-03-20 23:33:24+00:00\n",
      "13                 ld_data/adult22.csv  27432.139648 2025-03-20 23:33:26+00:00\n",
      "14                 ld_data/adult23.csv  28708.598633 2025-03-20 23:33:28+00:00\n"
     ]
    }
   ],
   "source": [
    "# list objects in bucket\n",
    "s3 = boto3.client(\"s3\") \n",
    "bucket_name = \"usd-team1-ads508\"\n",
    "response = s3.list_objects_v2(Bucket=bucket_name)\n",
    "\n",
    "# extract file details\n",
    "if \"Contents\" in response:\n",
    "    file_list = [{\"Key\": obj[\"Key\"], \"Size (KB)\": obj[\"Size\"] / 1024, \"Last Modified\": obj[\"LastModified\"]} for obj in response[\"Contents\"]]\n",
    "\n",
    "    # convert to pandas df\n",
    "    df_files = pd.DataFrame(file_list) \n",
    "\n",
    "    # display \n",
    "    print(df_files) \n",
    "else: \n",
    "    print(\"No files founds in the S3 bucket.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4865a53-95ac-4e0e-ab9d-7d5048324c38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
